# -*- coding: utf-8 -*-
"""RandomForestToxicity

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQVIDoun1ZvuyVa916Qr_CayRXto6_9Y

Audio Text Generator
"""

# Prepare environment
import os

# if not os.path.isfile("_installed"):
#   !pip install spacy dash jupyter-dash pandas==1.2.0 mne[data] mne gdown yt-dlp webvtt-py librosa vosk detoxify > /dev/null
#   !python -m spacy download en_core_web_sm
#   !apt install p7zip -y > /dev/null
#   !echo installed >> _installed

# Common imports
import sys, os, time

# Module imports
import pandas as pd
import spacy as sp
import numpy as np
import mne
import dash
from dash import html, dcc
from jupyter_dash import JupyterDash
import numpy as np # We might need it.
from dash import dash_table

# Matplotlib (alternative to dash for simple debugging graphs)
import matplotlib.pyplot as plt
import heapq
import pickle

print("hello!")
"""Get the mints data

"""

to_open = "MINTS.zip" # Replace with LargeMINTS.zip for the large dataset
nlp_data = "large_nlp_data" if "Large" in to_open else "nlp_data"

FILE_PATH = "./2022_01_14_T04_U002_EEG01/2022_01_14_T04_U002_EEG01.vhdr"

if not os.path.exists(os.path.join(nlp_data, FILE_PATH)):
    print("No", nlp_data, "directory found! Try using a password to extract the zipfile that's hopefully in ../data")
    print("...or you could just unzip the MINTS.zip file into a directory called", nlp_data, "in the CWD")

    ap = argparse.ArgumentParser(description="Visualize EEG data")

    ap.add_argument("zip_password", help="The password for the MINTS zip (not included for security reasons)")

    args = ap.parse_args()

    zip_password = args.zip_password

    root_dir = os.path.split(os.path.abspath("."))[0]
    zip_path = os.path.join(root_dir, "data", to_open)
    os.makedirs(nlp_data, exist_ok=True)

    print("Attempting to call 7zip")
    subprocess.check_call(["7z", "-y", "x", "-p" + zip_password, zip_path], cwd=os.path.abspath(nlp_data))


# Import them
# from read_data import *

from detoxify import Detoxify

def get_toxicity_of_text(text):
  results = Detoxify('original').predict(text)
  df = pd.DataFrame(results, index=[0])
  df = df * 100
  print('got toxicity of', text)
  return float(df['toxicity'])

"""Grab the EEG data"""

def read_eeg(vhdr_fname):
    # define list of indicies for non-eeg channels
    misc_list = []
    for i in range(18):
        misc_list.append(i+64)

    # read raw data
    raw = mne.io.read_raw_brainvision(vhdr_fname, misc=misc_list, preload=True,
        verbose=False)
    raw.info['line_freq'] = 500.

    # Set montage
    montage = mne.channels.make_standard_montage('easycap-M1')
    raw.set_montage(montage, verbose=False)

    # Set common average reference
    raw.set_eeg_reference('average', projection=False, verbose=False)

    # create pandas dataframe with eeg data
    df_eeg_data = pd.DataFrame(raw.get_data().transpose(), columns=raw.ch_names)

    # Trigger to sync with tobii eye data
    trig_tob = df_eeg_data.loc[df_eeg_data['TRIGGER'] == 3]
    start_tob = trig_tob.index[0]
    df_eeg_data = df_eeg_data.iloc[start_tob:, :]
    df_eeg_data.reset_index(inplace=True)

    # create time index - round to integer to match with transcript data
    times = list(range(len(df_eeg_data.index)))
    times = [int(t / 500) for t in times]
    df_eeg_data['Time'] = times

    # trigger for data during youtube video
    temp =  df_eeg_data.loc[df_eeg_data['TRIGGER'] == 8888]
    #youtube_start = df_eeg_data.loc[df_eeg_data['TRIGGER'] == 8888].index[0]
    youtube_end = temp.index[len(temp.index) - 1]
    df_eeg_data = df_eeg_data.iloc[:youtube_end + 1, :]
    #print(df_eeg_data_youtube)

    df_eeg_data = df_eeg_data.loc[:, ~df_eeg_data.columns.isin(['T7', 'TRIGGER', 'ACC79', 'Packet Counter',
                                                              'ACC77', 'ACC78', 'AUX 2', 'AUX 1', 'index'])]

    # sync up time with youtube video
    #df_eeg_data_youtube['Time'] = df_eeg_data_youtube['Time'] - df_eeg_data_youtube.iloc[0]['Time'] + 1
    #df_eeg_data_youtube['Time'] = df_eeg_data_youtube['Time'].astype(int)

    return df_eeg_data

df_eeg_data = read_eeg("./nlp_data/2022_01_14_T04_U002_EEG01/2022_01_14_T04_U002_EEG01.vhdr")
print("loaded data")

# df_eeg_data

"""# Now we try to do fourier transforms on the eeg data"""

# first try to isolate just one channel and plot some things

# just for testing, done now
# f = df_eeg_data['CP4']
# mean_f = np.mean(f)
# print(mean_f)
# f = (f/mean_f)
# plt.plot(df_eeg_data['Time'], f)
# plt.show()

# n = len(f)
# fhat = np.fft.fft(f)
# PSD = fhat * np.conj(fhat) /  n
# freq = (1/(n)) * np.arange(n)

# print(type(freq), freq.shape)
# print(type(PSD), PSD.shape)
# plt.plot(freq, PSD)
# plt.show()

# cutoff = (np.array(heapq.nlargest(7, PSD)))[-1]
# indices = PSD >= cutoff
# print(np.count_nonzero(indices))
# PSDclean = PSD*indices
# fhat = indices * fhat
# ffilt = np.fft.ifft(fhat)

# plt.plot(df_eeg_data['Time'], ffilt)
# plt.show()

# plt.plot(df_eeg_data.iloc[:,8])
# plt.plot(df_eeg_data['CP3'])
# plt.show()

def fourier_column(fft_df, column):
  f = fft_df[column]
  # mean_f = np.mean(f)
  # f = (f/mean_f)
  n = len(f)
  fhat = np.fft.fft(f)
  PSD = fhat * np.conj(fhat) /  n
  cutoff = (np.array(heapq.nlargest(10, PSD)))[-1]
  indices = PSD >= cutoff
  PSDclean = PSD*indices
  fhat = indices * fhat
  ffilt = np.fft.ifft(fhat)
  fft_df[column] = ffilt.real
  return (fft_df, column)

fft_df = df_eeg_data.copy()
column_headers_that_got_ffted = []
for i in range(0, 63):
  fft_df, col_name = fourier_column(fft_df, fft_df.columns[i])
  column_headers_that_got_ffted.append(col_name)
print('did fft on', column_headers_that_got_ffted)

# just to show fft
# plt.plot(fft_df['CP3'])
# # plt.plot(df_eeg_data.iloc[:,8])
# plt.show()

df_eeg_data = fft_df

"""Grab the audio file"""

yt_wav = "BadTalk.wav"

os.system(f"yt-dlp -x --audio-format wav --audio-quality 0 --write-auto-subs -o {yt_wav} https://www.youtube.com/watch?v=nGS8_R79vls")

import webvtt
vtt = webvtt.read(yt_wav + ".en.vtt")

samplerate=500

def ts_to_frameno(ts):
  # Converts a 00:00:00.000 timestamp into a frame number
  hrs, mins, secs = ts.split(":")
  total = int(hrs) * 3600 + int(mins) * 60 + float(secs)
  frameno = int(total * samplerate)
  return frameno

import re
cap_re = re.compile(r"<(?P<time>\d{2}:\d{2}:\d+\.\d+)><c>(?P<text>[^<]+)</c>")

# Clearly, not the most efficient way of doing it, but it works
frame_to_caption = [0] * len(df_eeg_data)
caption_text = ['']

for caption in vtt:
  # print(caption)
  frame_start = ts_to_frameno(caption.start)
  frame_end = ts_to_frameno(caption.end)
  words = []

  for word_start, word_text in cap_re.findall(caption.raw_text):
    word_start = ts_to_frameno(word_start)
    word_text = word_text.strip()
    if not word_text: continue

    words.append((word_start, word_text))

  bad_guess = False
  if len(words) == 0 and caption.text.strip():
    words.append((frame_start, caption.text.strip()))
    bad_guess = True

  for i, (word_start, word_text) in enumerate(words):
    if i == len(words) - 1:
      word_end = frame_end
    else:
      word_end = words[i + 1][0] - 1

    for i in range(frame_start, min(len(df_eeg_data), word_end + 1)):
      frame_to_caption[i] = len(caption_text) if (frame_to_caption[i] == 0 or not bad_guess) else frame_to_caption[i]
    caption_text.append(word_text)

# try to fix weird offset in the caption numbering
for i in range(0, len(frame_to_caption)):
  if((caption_text[frame_to_caption[i]]).count(" ") == 0):
    frame_to_caption[i] += 1
  if(frame_to_caption[i] >= len(caption_text)):
    frame_to_caption[i] = len(caption_text)-1
# print(sum(frame_to_caption))
df_eeg_data["Caption"] = frame_to_caption

df_eeg_data

def get_toxicity_of_cap_num(caption_number):
  return get_toxicity_of_text(caption_text[int(caption_number)])

# print(len(caption_text))
relevant_caption_nums = df_eeg_data['Caption'].unique()
# print(relevant_caption_nums)
# for num in relevant_caption_nums:
#   print(num, '\t', caption_text[num])

# print(caption_text[1])

caption_toxicity_pickle_name = "caption_toxicity.pickle"
if not os.path.exists(caption_toxicity_pickle_name):
    print("could not find the caption toxicity pickle, trying to download..")
    os.system(f"curl https://personal.utdallas.edu/~rdc180001/{caption_toxicity_pickle_name} --insecure > {caption_toxicity_pickle_name}")

with open(caption_toxicity_pickle_name, 'rb') as f:
  toxicity_for_num = pickle.load(f)

# use above to grab the pickled toxicity_for_num list (demo purposes), if a new one needs to be generated, use below
# toxicity_for_num = {}
# for num in relevant_caption_nums:
#   toxicity_for_num[num] = get_toxicity_of_cap_num(num)
# toxicity_for_num

def get_toxicity_memoized(df_cap_num):
  return toxicity_for_num[df_cap_num]

df_eeg_data['toxicity'] = df_eeg_data['Caption'].apply(get_toxicity_memoized)

def build_X():
  X = pd.DataFrame()
  for i in range(df_eeg_data.shape[1]-3):
    X[df_eeg_data.columns[i]] = (df_eeg_data[df_eeg_data.columns[i]] - df_eeg_data[df_eeg_data.columns[i]].min()) /(df_eeg_data[df_eeg_data.columns[i]].max() - df_eeg_data[df_eeg_data.columns[i]].min())
  return X



df_eeg_data.shape[1]
X = build_X()
X

y = df_eeg_data['toxicity']
y

"""Now we have full X and full Y, let's create a train/test split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

"""Next let's train the random forest regressor"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from numpy import sqrt

regressor_pickle_name = "regressor_pure_values.pickle"
if not os.path.exists(regressor_pickle_name):
    print("could not find the caption toxicity pickle, trying to download..")
    os.system(f"curl https://personal.utdallas.edu/~rdc180001/{regressor_pickle_name} --insecure > {regressor_pickle_name}")

with open(regressor_pickle_name, 'rb') as f:
  regressor = pickle.load(f)

# use above to grab the pickled regressor (demo purposes), if a new one needs to be generated, use below

# regressor = RandomForestRegressor(n_estimators = 100, random_state = 29, verbose=0)
# regressor.fit(X_train.values, y_train.values)

score=regressor.score(X_train.values, y_train.values)
train_pred = regressor.predict(X_train.values)
train_mse = mean_squared_error(y_train, train_pred)
print("**********Evaluating the Model on the training set**********************")
print("Model score (R-squared): %.2f" % score)
print("MSE: %.2f" % train_mse)
print("RMSE: %.2f" % sqrt(train_mse))

score=regressor.score(X_test.values, y_test.values)
y_pred = regressor.predict(X_test.values)
mse = mean_squared_error(y_test, y_pred)
print("**********Evaluating the Model on the test set**********************")
print("Model score (R-squared): %.2f" % score)
print("MSE: %.2f" % mse)
print("RMSE: %.2f" % sqrt(mse))

y_test_np = y_test.to_numpy()
num_right = 0
num_wrong = 0
for idx in range(0, len(y_pred)):
  diff = abs(y_pred[idx] - y_test_np[idx])
  if(diff < 1):
    num_right += 1
  else:
    num_wrong += 1
print("**********Test set # correct predictions, # wrong predictions**********")
print(num_right, num_wrong)
print("**********Test set accurarcy**********")
print(num_right/(num_right+num_wrong))

print("********Histogram of the toxicity in the test data***********")
plt.hist(y_test)
plt.title('Histogram of toxicity in the test data')
plt.ylabel('# of timesteps')
plt.xlabel('toxicity score')
plt.show()

print("********Histogram of the toxicity of the predictions using the test data***********")
plt.title('Histogram of toxicity in the predictions of the test data')
plt.ylabel('# of timesteps')
plt.xlabel('toxicity score')
plt.hist(y_pred)
plt.show()

# print(len(y_pred))
plt.scatter(y_pred, y_test)
bound_x = np.linspace(0, 100, 100)
ubound_y = 20+bound_x
lbound_y =-20+bound_x
plt.plot(bound_x, ubound_y, linestyle='--', color='red')
plt.plot(bound_x, lbound_y, linestyle='--', color='red')
plt.xlabel('Predicted toxicity')
plt.ylabel('Actual toxicity')
plt.show()

"""let's look at the mispredictions.."""

# bad_idxs = []
# for idx in range(0, len(y_pred)):
#   if(abs(y_pred[idx] - y_test_np[idx]) > 20):
#     print(idx,'\t(', y_pred[idx], ',',y_test_np[idx], ')\t', abs(y_pred[idx]-y_test_np[idx]))
#     bad_idxs.append(idx)

# mispredicted_test_caps = []
# for idx in bad_idxs:
#   mispredicted_test_caps.append(X_test.iloc[idx,:].name)
# # sorted(mispredicted_test_caps)
# df_eeg_data.iloc[9999].loc['Caption']
# caps = []
# for i in mispredicted_test_caps:
#   caps.append((int)(df_eeg_data.iloc[i].loc['Caption']))
# faulty_caps = []
# for i in (caps):
#   faulty_caps.append(caption_text[i])

# fault_cap = 0
# for idx in range(0, len(y_pred)):
#   if(abs(y_pred[idx] - y_test_np[idx]) > 20):
#     print(idx,'\t(', y_pred[idx], ',',y_test_np[idx], ')\t', (y_pred[idx]-y_test_np[idx]), '\t', mispredicted_test_caps[fault_cap], faulty_caps[fault_cap])
#     fault_cap += 1

# print(sorted(mispredicted_test_caps))
# df_eeg_data.iloc[44549].loc['Caption']

full_pred = regressor.predict(X.values)

print("********** (training + test set) predictions in green, actual toxicity in blue **********")
x_range = np.linspace(0, 111095, 111095)
plt.scatter(x_range, full_pred, color='green')
plt.scatter(x_range, y, color='blue')
plt.plot()
plt.show()

print("**********Relative importances**********")
# print(regressor.feature_importances_)
plt.bar(range(0, len(regressor.feature_importances_)), regressor.feature_importances_)
plt.show()

print("********** Importances of each feature **********")
importances = [(df_eeg_data.columns[x[0]], x[1]) for x in sorted(enumerate(regressor.feature_importances_), key=lambda x: x[1])[::-1]]

brainmap = {
    'Fpz':'Prefrontal Cortex',
    'Fp1':'Prefrontal Cortex',
    'Fp2':'Prefrontal Cortex',
    'AF7':'Prefrontal Cortex',
    'AF3':'Prefrontal Cortex',
    'AFz':'Prefrontal Cortex',
    'AF4':'Prefrontal Cortex',
    'AF8':'Prefrontal Cortex',
    'F7' :'Premotor Cortex',
    'F5':'Premotor Cortex',
    'F3':'Premotor Cortex',
    'F1':'Premotor Cortex',
    'Fz':'Premotor Cortex',
    'F2':'Premotor Cortex',
    'F4':'Premotor Cortex',
    'F6':'Premotor Cortex',
    'F8':'Premotor Cortex',
    'FT9':'Auditory Association Area',
    'FT7':'Brocas Area',
    'FC5':'Primary Motor Cortex',
    'FC3':'Primary Motor Cortex',
    'FC1':'Primary Motor Cortex',
    'FCz':'Primary Motor Cortex',
    'FC2':'Primary Motor Cortex',
    'FC4':'Primary Motor Cortex',
    'FC6':'Primary Motor Cortex',
    'FT8': 'Brocas Area',
    'FT10':'Auditory Association Area',
    'T7':'Auditory Cortex',
    'C5':'Primary Sensory Cortex',
    'C3':'Primary Sensory Cortex',
    'C1':'Primary Sensory Cortex',
    'Cz':'Primary Sensory Cortex',
    'C2':'Primary Sensory Cortex',
    'C4':'Primary Sensory Cortex',
    'C6':'Primary Sensory Cortex',
    'T8':'Auditory Cortex',
    'TP7':'Wernickes Area',
    'CP5':'Somatic Sensory Association Area',
    'CP3':'Somatic Sensory Association Area',
    'CP1':'Somatic Sensory Association Area',
    'CPz':'Somatic Sensory Association Area',
    'CP2':'Somatic Sensory Association Area',
    'CP4':'Somatic Sensory Association Area',
    'CP6':'Somatic Sensory Association Area',
    'TP8':'Wernickes Area',
    'TP10':'Wernickes Area',
    'P7':'Somatic Sensory Association Area',
    'P5':'Somatic Sensory Association Area',
    'P3':'Somatic Sensory Association Area',
    'P1':'Somatic Sensory Association Area',
    'Pz':'Somatic Sensory Association Area',
    'P2':'Somatic Sensory Association Area',
    'P4':'Somatic Sensory Association Area',
    'P6':'Somatic Sensory Association Area',
    'P8':'Somatic Sensory Association Area',
    'PO7':'Visual Association Area',
    'PO3':'Visual Association Area',
    'POz':'Visual Association Area',
    'PO4':'Visual Association Area',
    'PO8':'Visual Association Area',
    'O1':'Visual Cortex',
    'Oz':'Visual Cortex',
    'O2':'Visual Cortex',
    'REF':'NAN',
    'GND':'NAN'
    }
broadmannmapping ={
    'Fpz':'ba10L',
    'Fp1':'ba10L',
    'Fp2':'ba10R',
    'AF7':'ba46L',
    'AF3':'ba09L',
    'AFz':'ba09L',
    'AF4':'ba09R',
    'AF8':'ba46R',
    'F7' :'ba47L',
    'F5':'ba46L',
    'F3':'ba08L',
    'F1':'ba08L',
    'Fz':'ba08L',
    'F2':'ba08R',
    'F4':'ba08R',
    'F6':'ba46R',
    'F8':'ba45R',
    'FT9':'ba20L',
    'FT7':'ba47L',
    'FC5':'BROCLA',
    'FC3':'ba06L',
    'FC1':'ba06L',
    'FCz':'ba06R',
    'FC2':'ba06R',
    'FC4':'ba06R',
    'FC6':'ba44R',
    'FT8': 'ba47R',
    'FT10':'ba20R',
    'T7':'ba42L',
    'C5':'ba42L',
    'C3':'ba02L',
    'C1':'ba05L',
    'Cz':'ba05L',
    'C2':'ba05R',
    'C4':'ba01R',
    'C6':'ba41R',
    'T8':'ba21R',
    'TP7':'ba21L',
    'CP5':'ba40L',
    'CP3':'ba02L',
    'CP1':'ba05L',
    'CPz':'ba05R',
    'CP2':'ba05R',
    'CP4':'ba40R',
    'CP6':'ba40R',
    'TP8':'ba21R',
    'TP10':'ba21R',
    'P7':'ba37L',
    'P5':'ba39L',
    'P3':'ba39L',
    'P1':'ba07L',
    'Pz':'ba07R',
    'P2':'ba07R',
    'P4':'ba39R',
    'P6':'ba39R',
    'P8':'ba37R',
    'PO7':'ba19L',
    'PO3':'ba19L',
    'POz':'ba17L',
    'PO4':'ba19R',
    'PO8':'ba19R',
    'O1':'ba19L',
    'Oz':'ba17R',
    'O2':'ba18R',
    'REF':'NAN',
    'GND':'NAN'
    }
broadmanntoarea ={
    'ba01':'Primary Sensory Cortex',
    'ba02':'Primary Sensory Cortex',
    'ba03':'Primary Sensory Cortex',
    'ba04':'Primary Motor Cortex',
    'ba05':'Somatic Sensory Association Area',
    'ba06':'Premotor Cortex',
    'ba07':'Somatic Sensory Association Area',
    'ba08':'Prefrontal Cortex',
    'ba09':'Prefrontal Cortex',
    'ba10':'Prefrontal Cortex',
    'ba11':'Prefrontal Cortex',
    'ba12':'Prefrontal Cortex',
    'ba17':'Visual Cortex',
    'ba18':'Visual Cortex',
    'ba19':'Visual Association Area',
    'ba20':'Temporal',
    'ba21':'Temporal',
    'ba22':'Wernickes Area',
    'ba37':'Temporal',
    'ba38':'Temporal',
    'ba39':'Wernickes Area',
    'ba40':'Wernickes Area',
    'ba41':'Auditory Cortex',
    'ba42':'Auditory Cortex',
    'ba43':'Frontal Cortex',
    'ba44':'Frontal Cortex',
    'BROCL':'Brocas Area',
    'ba45':'Frontal Cortex',
    'ba46':'Frontal Cortex',
    'ba47':'Brocas Area',
    }
areamap = {
    'Prefrontal Cortex':'Involved in decision making and abstract thought',
    'Premotor Cortex':'Involved in planning of movement',
    'Brocas Area':'Responsible for speech production',
    'Auditory Cortex':'Processes sound',
    'Auditory Association Area':'Responsible for high level processing of sound, such as memory',
    'Primary Motor Cortex':'Executes Movement',
    'Primary Sensory Cortex':'Main receptive area for the senses, especially touch',
    'Wernickes Area':'Involved in understanding speech',
    'Somatic Sensory Association Area':'Involved in high level touch interpretation',
    'Visual Association Area':'Involved in high level processing of visual stimuli',
    'Visual Cortex':'Processes visual stimuli'
    }

for x in importances:
    if x[0] in brainmap:
        print(f"{x} in the {brainmap[x[0]]} ({broadmannmapping[x[0]]}) on the {broadmanntoarea[broadmannmapping[x[0]][:-1]]} which is {areamap.get(broadmanntoarea[broadmannmapping[x[0]][:-1]], 'Brain Activity')}")
    else:
        print(x)
